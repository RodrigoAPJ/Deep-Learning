{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "with zipfile.ZipFile('../input/notebook36cfb71da3/database-full.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('./data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.remove('./data/database-full/ image11396.jpg')\n",
    "import shutil\n",
    "shutil.rmtree('./data/__MACOSX')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance(X, y_, limit=15):\n",
    "    \n",
    "    balanced_X = []\n",
    "    balanced_y = []\n",
    "    \n",
    "    y = y_.squeeze()\n",
    "    for i in range(y.max()):\n",
    "        if( len(y[y == i]) > limit):\n",
    "            balanced_X.append(X[y == i][:limit])\n",
    "            balanced_y.append(y[y == i][:limit])\n",
    "        else:\n",
    "            balanced_X.append(X[y == i])\n",
    "            balanced_y.append(y[y == i])\n",
    "            \n",
    "    return np.array([y for x in balanced_X for y in x]), np.array([[y] for x in balanced_y for y in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../input/aux-cluster/aux_cluster.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_unlabeled = ['./data/database-full/' + x for x in os.listdir('./data/database-full/') if x not in df.ID]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_labeled = np.array(['./data/database-full/' + filename for filename in df.ID])\n",
    "y_labeled = df.new_cluster.values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_labeled, y_labeled = balance(X_labeled, y_labeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_labeled, y_labeled, stratify = y_labeled, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val = y_val.squeeze()\n",
    "y_train = y_train.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset hyperparameters\n",
    "unlabeled_dataset_size = len(X_unlabeled)\n",
    "labeled_dataset_size = len(X_labeled)\n",
    "image_size = 256\n",
    "image_channels = 3\n",
    "\n",
    "# Algorithm hyperparameters\n",
    "num_epochs = 20\n",
    "batch_size = 24\n",
    "width = 128\n",
    "temperature = 0.1\n",
    "# Stronger augmentations for contrastive, weaker ones for supervised training\n",
    "contrastive_augmentation = {\"min_area\": 0.25, \"brightness\": 0.6, \"jitter\": 0.2}\n",
    "classification_augmentation = {\"min_area\": 0.75, \"brightness\": 0.3, \"jitter\": 0.1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_from_path(path):\n",
    "    \n",
    "    image = tf.io.read_file(path)\n",
    "    image = tf.io.decode_jpeg(image)\n",
    "    image = tf.image.resize(image, size = (image_size, image_size))\n",
    "    \n",
    "    return image/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset():\n",
    "    # Labeled and unlabeled samples are loaded synchronously\n",
    "    # with batch sizes selected accordingly\n",
    "    steps_per_epoch = (unlabeled_dataset_size + labeled_dataset_size) // batch_size\n",
    "    unlabeled_batch_size = unlabeled_dataset_size // steps_per_epoch\n",
    "    labeled_batch_size = labeled_dataset_size // steps_per_epoch\n",
    "    print(\n",
    "        f\"batch size is {unlabeled_batch_size} (unlabeled) + {labeled_batch_size} (labeled)\"\n",
    "    )\n",
    "\n",
    "    \n",
    "    unlabeled_train_dataset = tf.data.Dataset.from_tensor_slices(X_unlabeled)\n",
    "    unlabeled_train_dataset = (\n",
    "        unlabeled_train_dataset.shuffle(buffer_size=10 * unlabeled_batch_size)\n",
    "        .map(load_image_from_path)\n",
    "        .batch(unlabeled_batch_size)\n",
    "    )\n",
    "    \n",
    "    \n",
    "    labeled_train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "    labeled_train_dataset = (\n",
    "        labeled_train_dataset.shuffle(buffer_size=10 * labeled_batch_size)\n",
    "        .map(lambda x, y: (load_image_from_path(x), y))\n",
    "        .batch(labeled_batch_size)\n",
    "    )\n",
    "    \n",
    "    test_dataset = tf.data.Dataset.from_tensor_slices((X_val, y_val))\n",
    "    test_dataset = (\n",
    "        test_dataset\n",
    "        .map(lambda x, y: (load_image_from_path(x), y))\n",
    "        .batch(batch_size)\n",
    "        .prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "    )\n",
    "\n",
    "    # Labeled and unlabeled datasets are zipped together\n",
    "    train_dataset = tf.data.Dataset.zip(\n",
    "        (unlabeled_train_dataset, labeled_train_dataset)\n",
    "    ).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "    return train_dataset, labeled_train_dataset, test_dataset\n",
    "\n",
    "\n",
    "train_dataset, labeled_train_dataset, test_dataset = prepare_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distorts the color distibutions of images\n",
    "class RandomColorAffine(layers.Layer):\n",
    "    def __init__(self, brightness=0, jitter=0, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        self.brightness = brightness\n",
    "        self.jitter = jitter\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\"brightness\": self.brightness, \"jitter\": self.jitter})\n",
    "        return config\n",
    "\n",
    "    def call(self, images, training=True):\n",
    "        if training:\n",
    "            batch_size = tf.shape(images)[0]\n",
    "\n",
    "            # Same for all colors\n",
    "            brightness_scales = 1 + tf.random.uniform(\n",
    "                (batch_size, 1, 1, 1), minval=-self.brightness, maxval=self.brightness\n",
    "            )\n",
    "            # Different for all colors\n",
    "            jitter_matrices = tf.random.uniform(\n",
    "                (batch_size, 1, 3, 3), minval=-self.jitter, maxval=self.jitter\n",
    "            )\n",
    "\n",
    "            color_transforms = (\n",
    "                tf.eye(3, batch_shape=[batch_size, 1]) * brightness_scales\n",
    "                + jitter_matrices\n",
    "            )\n",
    "            images = tf.clip_by_value(tf.matmul(images, color_transforms), 0, 1)\n",
    "        return images\n",
    "\n",
    "\n",
    "# Image augmentation module\n",
    "def get_augmenter(min_area, brightness, jitter):\n",
    "    zoom_factor = 1.0 - math.sqrt(min_area)\n",
    "    return keras.Sequential(\n",
    "        [\n",
    "            keras.Input(shape=(image_size, image_size, image_channels)),\n",
    "            #layers.Rescaling(1. / 255.),\n",
    "            layers.RandomFlip(\"horizontal\"),\n",
    "            layers.RandomTranslation(zoom_factor / 2, zoom_factor / 2),\n",
    "            layers.RandomZoom((-zoom_factor, 0.0), (-zoom_factor, 0.0)),\n",
    "            RandomColorAffine(brightness, jitter),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "def visualize_augmentations(num_images):\n",
    "    # Sample a batch from a dataset\n",
    "    images = next(iter(train_dataset))[0][:num_images]\n",
    "    # Apply augmentations\n",
    "    augmented_images = zip(\n",
    "        images,\n",
    "        get_augmenter(**classification_augmentation)(images),\n",
    "        get_augmenter(**contrastive_augmentation)(images),\n",
    "        get_augmenter(**contrastive_augmentation)(images),\n",
    "    )\n",
    "    row_titles = [\n",
    "        \"Original:\",\n",
    "        \"Weakly augmented:\",\n",
    "        \"Strongly augmented:\",\n",
    "        \"Strongly augmented:\",\n",
    "    ]\n",
    "    plt.figure(figsize=(num_images * 2.2, 4 * 2.2), dpi=100)\n",
    "    for column, image_row in enumerate(augmented_images):\n",
    "        for row, image in enumerate(image_row):\n",
    "            plt.subplot(4, num_images, row * num_images + column + 1)\n",
    "            plt.imshow(image)\n",
    "            if column == 0:\n",
    "                plt.title(row_titles[row], loc=\"left\")\n",
    "            plt.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "visualize_augmentations(num_images=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the encoder architecture\n",
    "def get_encoder():\n",
    "    return keras.Sequential(\n",
    "        [\n",
    "            keras.Input(shape=(image_size, image_size, image_channels)),\n",
    "            layers.Conv2D(width, kernel_size=3, strides=2, activation=\"relu\"),\n",
    "            layers.Conv2D(width, kernel_size=3, strides=2, activation=\"relu\"),\n",
    "            layers.Conv2D(width, kernel_size=3, strides=2, activation=\"relu\"),\n",
    "            layers.Conv2D(width, kernel_size=3, strides=2, activation=\"relu\"),\n",
    "            layers.Flatten(),\n",
    "            layers.Dense(width, activation=\"relu\"),\n",
    "        ],\n",
    "        name=\"encoder\",\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline supervised training with random initialization\n",
    "baseline_model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(image_size, image_size, image_channels)),\n",
    "        get_augmenter(**classification_augmentation),\n",
    "        get_encoder(),\n",
    "        layers.Dense(167),\n",
    "    ],\n",
    "    name=\"baseline_model\",\n",
    ")\n",
    "baseline_model.compile(\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[keras.metrics.SparseCategoricalAccuracy(name=\"acc\")],\n",
    ")\n",
    "\n",
    "baseline_history = baseline_model.fit(\n",
    "    labeled_train_dataset, epochs=num_epochs, validation_data=test_dataset\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"Maximal validation accuracy: {:.2f}%\".format(\n",
    "        max(baseline_history.history[\"val_acc\"]) * 100\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the contrastive model with model-subclassing\n",
    "class ContrastiveModel(keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.temperature = temperature\n",
    "        self.contrastive_augmenter = get_augmenter(**contrastive_augmentation)\n",
    "        self.classification_augmenter = get_augmenter(**classification_augmentation)\n",
    "        self.encoder = get_encoder()\n",
    "        # Non-linear MLP as projection head\n",
    "        self.projection_head = keras.Sequential(\n",
    "            [\n",
    "                keras.Input(shape=(width,)),\n",
    "                layers.Dense(width, activation=\"relu\"),\n",
    "                layers.Dense(width),\n",
    "            ],\n",
    "            name=\"projection_head\",\n",
    "        )\n",
    "        # Single dense layer for linear probing\n",
    "        self.linear_probe = keras.Sequential(\n",
    "            [layers.Input(shape=(width,)), layers.Dense(167)], name=\"linear_probe\"\n",
    "        )\n",
    "\n",
    "        self.encoder.summary()\n",
    "        self.projection_head.summary()\n",
    "        self.linear_probe.summary()\n",
    "\n",
    "    def compile(self, contrastive_optimizer, probe_optimizer, **kwargs):\n",
    "        super().compile(**kwargs)\n",
    "\n",
    "        self.contrastive_optimizer = contrastive_optimizer\n",
    "        self.probe_optimizer = probe_optimizer\n",
    "\n",
    "        # self.contrastive_loss will be defined as a method\n",
    "        self.probe_loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "        self.contrastive_loss_tracker = keras.metrics.Mean(name=\"c_loss\")\n",
    "        self.contrastive_accuracy = keras.metrics.SparseCategoricalAccuracy(\n",
    "            name=\"c_acc\"\n",
    "        )\n",
    "        self.probe_loss_tracker = keras.metrics.Mean(name=\"p_loss\")\n",
    "        self.probe_accuracy = keras.metrics.SparseCategoricalAccuracy(name=\"p_acc\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.contrastive_loss_tracker,\n",
    "            self.contrastive_accuracy,\n",
    "            self.probe_loss_tracker,\n",
    "            self.probe_accuracy,\n",
    "        ]\n",
    "\n",
    "    def contrastive_loss(self, projections_1, projections_2):\n",
    "        # InfoNCE loss (information noise-contrastive estimation)\n",
    "        # NT-Xent loss (normalized temperature-scaled cross entropy)\n",
    "\n",
    "        # Cosine similarity: the dot product of the l2-normalized feature vectors\n",
    "        projections_1 = tf.math.l2_normalize(projections_1, axis=1)\n",
    "        projections_2 = tf.math.l2_normalize(projections_2, axis=1)\n",
    "        similarities = (\n",
    "            tf.matmul(projections_1, projections_2, transpose_b=True) / self.temperature\n",
    "        )\n",
    "\n",
    "        # The similarity between the representations of two augmented views of the\n",
    "        # same image should be higher than their similarity with other views\n",
    "        batch_size = tf.shape(projections_1)[0]\n",
    "        contrastive_labels = tf.range(batch_size)\n",
    "        self.contrastive_accuracy.update_state(contrastive_labels, similarities)\n",
    "        self.contrastive_accuracy.update_state(\n",
    "            contrastive_labels, tf.transpose(similarities)\n",
    "        )\n",
    "\n",
    "        # The temperature-scaled similarities are used as logits for cross-entropy\n",
    "        # a symmetrized version of the loss is used here\n",
    "        loss_1_2 = keras.losses.sparse_categorical_crossentropy(\n",
    "            contrastive_labels, similarities, from_logits=True\n",
    "        )\n",
    "        loss_2_1 = keras.losses.sparse_categorical_crossentropy(\n",
    "            contrastive_labels, tf.transpose(similarities), from_logits=True\n",
    "        )\n",
    "        return (loss_1_2 + loss_2_1) / 2\n",
    "\n",
    "    def train_step(self, data):\n",
    "        unlabeled_images, (labeled_images, labels) = data\n",
    "\n",
    "        # Both labeled and unlabeled images are used, without labels\n",
    "        images = tf.concat((unlabeled_images, labeled_images), axis=0)\n",
    "        # Each image is augmented twice, differently\n",
    "        augmented_images_1 = self.contrastive_augmenter(images, training=True)\n",
    "        augmented_images_2 = self.contrastive_augmenter(images, training=True)\n",
    "        with tf.GradientTape() as tape:\n",
    "            features_1 = self.encoder(augmented_images_1, training=True)\n",
    "            features_2 = self.encoder(augmented_images_2, training=True)\n",
    "            # The representations are passed through a projection mlp\n",
    "            projections_1 = self.projection_head(features_1, training=True)\n",
    "            projections_2 = self.projection_head(features_2, training=True)\n",
    "            contrastive_loss = self.contrastive_loss(projections_1, projections_2)\n",
    "        gradients = tape.gradient(\n",
    "            contrastive_loss,\n",
    "            self.encoder.trainable_weights + self.projection_head.trainable_weights,\n",
    "        )\n",
    "        self.contrastive_optimizer.apply_gradients(\n",
    "            zip(\n",
    "                gradients,\n",
    "                self.encoder.trainable_weights + self.projection_head.trainable_weights,\n",
    "            )\n",
    "        )\n",
    "        self.contrastive_loss_tracker.update_state(contrastive_loss)\n",
    "\n",
    "        # Labels are only used in evalutation for an on-the-fly logistic regression\n",
    "        preprocessed_images = self.classification_augmenter(\n",
    "            labeled_images, training=True\n",
    "        )\n",
    "        with tf.GradientTape() as tape:\n",
    "            # the encoder is used in inference mode here to avoid regularization\n",
    "            # and updating the batch normalization paramers if they are used\n",
    "            features = self.encoder(preprocessed_images, training=False)\n",
    "            class_logits = self.linear_probe(features, training=True)\n",
    "            probe_loss = self.probe_loss(labels, class_logits)\n",
    "        gradients = tape.gradient(probe_loss, self.linear_probe.trainable_weights)\n",
    "        self.probe_optimizer.apply_gradients(\n",
    "            zip(gradients, self.linear_probe.trainable_weights)\n",
    "        )\n",
    "        self.probe_loss_tracker.update_state(probe_loss)\n",
    "        self.probe_accuracy.update_state(labels, class_logits)\n",
    "\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "\n",
    "    def test_step(self, data):\n",
    "        labeled_images, labels = data\n",
    "\n",
    "        # For testing the components are used with a training=False flag\n",
    "        preprocessed_images = self.classification_augmenter(\n",
    "            labeled_images, training=False\n",
    "        )\n",
    "        features = self.encoder(preprocessed_images, training=False)\n",
    "        class_logits = self.linear_probe(features, training=False)\n",
    "        probe_loss = self.probe_loss(labels, class_logits)\n",
    "        self.probe_loss_tracker.update_state(probe_loss)\n",
    "        self.probe_accuracy.update_state(labels, class_logits)\n",
    "\n",
    "        # Only the probe metrics are logged at test time\n",
    "        return {m.name: m.result() for m in self.metrics[2:]}\n",
    "\n",
    "\n",
    "# Contrastive pretraining\n",
    "pretraining_model = ContrastiveModel()\n",
    "pretraining_model.compile(\n",
    "    contrastive_optimizer=keras.optimizers.Adam(),\n",
    "    probe_optimizer=keras.optimizers.Adam(),\n",
    ")\n",
    "\n",
    "pretraining_history = pretraining_model.fit(\n",
    "    train_dataset, epochs=num_epochs, validation_data=test_dataset\n",
    ")\n",
    "print(\n",
    "    \"Maximal validation accuracy: {:.2f}%\".format(\n",
    "        max(pretraining_history.history[\"val_p_acc\"]) * 100\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supervised finetuning of the pretrained encoder\n",
    "finetuning_model = keras.Sequential(\n",
    "    [\n",
    "        layers.Input(shape=(image_size, image_size, image_channels)),\n",
    "        get_augmenter(**classification_augmentation),\n",
    "        pretraining_model.encoder,\n",
    "        layers.Dense(167),\n",
    "    ],\n",
    "    name=\"finetuning_model\",\n",
    ")\n",
    "finetuning_model.compile(\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=[keras.metrics.SparseCategoricalAccuracy(name=\"acc\")],\n",
    ")\n",
    "\n",
    "finetuning_history = finetuning_model.fit(\n",
    "    labeled_train_dataset, epochs=num_epochs, validation_data=test_dataset\n",
    ")\n",
    "print(\n",
    "    \"Maximal validation accuracy: {:.2f}%\".format(\n",
    "        max(finetuning_history.history[\"val_acc\"]) * 100\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuning_model.save('SimCLR.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = pd.read_csv('../input/taller3data/names_test_queries.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = np.array(['./data/database-full/' + name for name in queries.values]).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries_dataset = tf.data.Dataset.from_tensor_slices(queries)\n",
    "queries_dataset = (\n",
    "    queries_dataset\n",
    "    .map(load_image_from_path)\n",
    "    .batch(batch_size)\n",
    "    .prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = finetuning_model.predict(queries_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries_2 = pd.read_csv('../input/taller3data/names_test_queries.csv', header=None)\n",
    "\n",
    "queries_2['preds'] = preds.argmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all = ['./data/database-full/' + x for x in os.listdir('./data/database-full/')]\n",
    "\n",
    "all_dataset = tf.data.Dataset.from_tensor_slices(X_all)\n",
    "all_dataset = (\n",
    "    all_dataset\n",
    "    .map(load_image_from_path)\n",
    "    .batch(batch_size)\n",
    "    .prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_all = finetuning_model.predict(all_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_all = preds_all.argmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuning_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = keras.Sequential([l for l in finetuning_model.layers[:-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finetuning_model.compile(\n",
    "#     optimizer=keras.optimizers.Adam(),\n",
    "#     loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "#     metrics=[keras.metrics.SparseCategoricalAccuracy(name=\"acc\")],\n",
    "# )\n",
    "encode_preds = m.predict(all_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_SimCLR = pd.DataFrame({'paths': X_all, 'cluster': preds_all, 'encode': [x for x in encode_preds]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_SimCLR.to_csv('result_SimCLR_Kaggle.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_SimCLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len('./data/database-full/ image'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import pairwise_distances\n",
    "from tqdm import tqdm\n",
    "\n",
    "def sorting(tup, reverse=True):\n",
    "    return(sorted(tup, key = lambda x: x[0],reverse=reverse))\n",
    "\n",
    "for query in tqdm(queries):\n",
    "    cluster = result_SimCLR[result_SimCLR.paths == query].cluster.values[0]\n",
    "    \n",
    "    neighborhood = result_SimCLR[(result_SimCLR.cluster == cluster) & (result_SimCLR.paths != query)]\n",
    "    neighborhood_latents = np.array(neighborhood.encode.values)\n",
    "    query_latent = result_SimCLR[result_SimCLR.paths == query].encode.values[0]\n",
    "    \n",
    "    neighborhood_latents = np.array([x for x in neighborhood_latents])\n",
    "    \n",
    "    dist = pairwise_distances(query_latent.reshape(1, -1), neighborhood_latents, metric = 'cosine')[0] \n",
    "    dist_path = [(x, y) for x, y in zip(dist, neighborhood.paths)]\n",
    "    \n",
    "    sorted_dist_path = np.array(sorting(dist_path, False))[:,1][:100]\n",
    "    indices = result_SimCLR[result_SimCLR.paths == query].index\n",
    "    sorted_dist_path = [x[27:-4] for x in sorted_dist_path]\n",
    "    to_add = \" \".join(sorted_dist_path)\n",
    "    \n",
    "    result_SimCLR.loc[indices, 'most_similars'] = to_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IDs = [x[27:-4] for x in result_SimCLR[result_SimCLR.paths.isin(queries)].paths.values]\n",
    "Expecteds = result_SimCLR[result_SimCLR.paths.isin(queries)].most_similars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_df = pd.DataFrame({'Id': IDs, 'Expected':Expecteds}).set_index('Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_queries = [x[27:-4] for x in queries]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_submit = pd.DataFrame(columns=['Id', 'Expected'])\n",
    "for i in indices_queries:\n",
    "    final_submit = final_submit.append(submit_df[submit_df.index == i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_submit = final_submit.reset_index().drop('Id', axis=1).rename(columns={'index':'Id'}).set_index('Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_submit.to_csv(\"SimCLR.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
