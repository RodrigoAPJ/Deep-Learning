{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hipotesis:\n",
    "\n",
    "    En problemas de clasificación de sentimiento, entrenar una red para realizar POS-tagging como tarea auxiliar contribuye a mejorar el desempeño en la tarea principal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Rod\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package treebank to\n",
      "[nltk_data]     C:\\Users\\Rod\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package treebank is already up-to-date!\n",
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\Rod\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package conll2000 to\n",
      "[nltk_data]     C:\\Users\\Rod\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package conll2000 is already up-to-date!\n",
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     C:\\Users\\Rod\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package universal_tagset is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import pos_tag\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "import re\n",
    "nltk.download('treebank')\n",
    "nltk.download('brown')\n",
    "nltk.download('conll2000')\n",
    "nltk.download('universal_tagset')\n",
    "from nltk.corpus import brown\n",
    "from nltk.corpus import treebank\n",
    "from nltk.corpus import conll2000\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout, LSTM, Bidirectional, GRU, BatchNormalization,Embedding\n",
    "from keras.layers import Dense, Conv1D, MaxPooling1D\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ¿Qué es Pos tag?\n",
    "\n",
    "Pos tag = part of speech tag, significa etiquetar las palabras de un texto dependiendo si son adjetivos, verbos, pronombres, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generacion de dataset\n",
    "\n",
    "Con ayuda de la libreria NLTK se genero un dataset en base a los corpus (cuerpos de texto general) que contiene sus respectivas etiquetas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treebank_corpus = treebank.tagged_sents(tagset='universal')\n",
    "brown_corpus = brown.tagged_sents(tagset='universal')\n",
    "conll_corpus = conll2000.tagged_sents(tagset='universal')\n",
    "tagged_sentences = treebank_corpus + brown_corpus + conll_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [] \n",
    "Y = [] \n",
    "\n",
    "for sentence in tagged_sentences:\n",
    "    X_sentence = []\n",
    "    Y_sentence = []\n",
    "    for entity in sentence:         \n",
    "        X_sentence.append(entity[0]) \n",
    "        Y_sentence.append(entity[1])  \n",
    "        \n",
    "    X.append(X_sentence)\n",
    "    Y.append(Y_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenización de las palabras\n",
    "\n",
    "A cada palabra se le asigna un número id para representarla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_tokenizer = Tokenizer()                    \n",
    "word_tokenizer.fit_on_texts(X)                   \n",
    "X_encoded = word_tokenizer.texts_to_sequences(X) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_tokenizer = Tokenizer()\n",
    "tag_tokenizer.fit_on_texts(Y)\n",
    "Y_encoded = tag_tokenizer.texts_to_sequences(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Padding de textos\n",
    "\n",
    "Limitamos el largo a 100 palabras por oración y aquellas con menor cantidad a 100 se le agregan ceros para que queden del mismo tamaño"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQ_LENGTH = 100\n",
    "X_padded = pad_sequences(X_encoded, maxlen=MAX_SEQ_LENGTH, padding=\"pre\", truncating=\"post\")\n",
    "Y_padded = pad_sequences(Y_encoded, maxlen=MAX_SEQ_LENGTH, padding=\"pre\", truncating=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = X_padded, Y_padded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encodeo de tags (requerido por el modelo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = to_categorical(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_SIZE  = 100 \n",
    "VOCABULARY_SIZE = len(word_tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = Y.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 100, 100)          5944900   \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 100, 64)           42240     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 100, 13)           845       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,987,985\n",
      "Trainable params: 5,987,985\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "postag_model = Sequential()\n",
    "# Embedding para tener una mejor representación del texto a procesar\n",
    "postag_model.add(Embedding(input_dim     = VOCABULARY_SIZE,\n",
    "                         output_dim    = EMBEDDING_SIZE,          \n",
    "                         input_length  = MAX_SEQ_LENGTH, \n",
    "                         mask_zero=True\n",
    "                        ))\n",
    "postag_model.add(LSTM(64, return_sequences=True))\n",
    "postag_model.add((Dense(NUM_CLASSES, activation='softmax')))\n",
    "postag_model.compile(loss      =  'categorical_crossentropy',\n",
    "                   optimizer =  'adam',\n",
    "                   metrics   =  ['accuracy'])\n",
    "postag_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "452/452 [==============================] - 170s 364ms/step - loss: 0.1533 - accuracy: 0.7837 - val_loss: 0.0350 - val_accuracy: 0.9468\n",
      "Epoch 2/5\n",
      "452/452 [==============================] - 195s 433ms/step - loss: 0.0262 - accuracy: 0.9580 - val_loss: 0.0274 - val_accuracy: 0.9544\n",
      "Epoch 3/5\n",
      "452/452 [==============================] - 207s 457ms/step - loss: 0.0193 - accuracy: 0.9673 - val_loss: 0.0259 - val_accuracy: 0.9565\n",
      "Epoch 4/5\n",
      "452/452 [==============================] - 210s 465ms/step - loss: 0.0165 - accuracy: 0.9714 - val_loss: 0.0256 - val_accuracy: 0.9572\n",
      "Epoch 5/5\n",
      "452/452 [==============================] - 214s 473ms/step - loss: 0.0146 - accuracy: 0.9749 - val_loss: 0.0259 - val_accuracy: 0.9575\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ea2e99cfa0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "postag_model.fit(X_train, Y_train, batch_size=128, epochs=5, validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaner(text):\n",
    "    text=text.lower()\n",
    "    for c in \"\\n\":\n",
    "        text = text.replace(c,\" \")\n",
    "    abrev = re.compile(r\"'\\b\\w+\\b\")\n",
    "    text = abrev.sub(r'',text).strip()\n",
    "    \n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    text = re.sub(r'#\\S+', '', text)\n",
    "    text = re.sub(r'@\\S+', '', text)\n",
    "    \n",
    "    tag = re.compile(r'<.*?>')\n",
    "    text = tag.sub(r' ',text).strip()\n",
    "    for c in \"!#$%&\\°'()*+,-./:;<=>?@[\\\\]^_{|}~`ø÷´¨\\\"\":\n",
    "        text = text.replace(c,\"\")\n",
    "        \n",
    "    #text = \" \".join([lemmatizer.lemmatize(word) for word in text.split()])                          \n",
    "    text = \" \".join([word for word in str(text).split() if word not in STOPWORDS])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon review sentiment\n",
    "\n",
    "Reviews sobre alimentos entregados por amazon donode los usuarios le entregan una puntuacion de 1 a 5\n",
    "https://www.kaggle.com/code/laowingkin/amazon-fine-food-review-sentiment-analysis/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('data1/data1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1[['Score', 'Text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(568454, 2)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 1, 4, 2, 3], dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.Score.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Balanceo de clases\n",
    "Especificamente la clase '5' que era considerablemente mas abundante que las demas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sub sampleamos score == 5 dado que esta altamente desbalanceado\n",
    "score_5 = df1[df1.Score==5]\n",
    "df1 = df1[~df1.index.isin(score_5.index)]\n",
    "score_5 = score_5.sample(frac=.25)\n",
    "df1 = pd.concat([df1, score_5], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpiando el texto\n",
    "df1.Text = df1.Text.apply(lambda x : cleaner(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_amz = df1.Text\n",
    "Y_amz = df1.Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Y_cat = to_categorical(Y_amz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distribucion de clases (balanceada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1728x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(24,12))\n",
    "plt.title('Balance', size=16)\n",
    "sns.countplot(x=Y_amz)\n",
    "plt.ylabel('Count', size=12)\n",
    "plt.xlabel('Label', size=12)\n",
    "plt.xticks(rotation=90)\n",
    "sns.despine(top=True, right=True, left=False, bottom=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoding label\n",
    "encoder = OneHotEncoder()\n",
    "Y_cat=encoder.fit_transform(Y_amz.values.reshape(-1,1)).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amz_X_train, amz_X_test, amz_y_train, amz_y_test = train_test_split(X_amz, Y_cat, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizando las reviews (con el vocabulario del modelo de pos tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amz_X_train_tk = word_tokenizer.texts_to_sequences(amz_X_train)\n",
    "amz_X_test_tk = word_tokenizer.texts_to_sequences(amz_X_test)\n",
    "\n",
    "amz_vocab_len = len(word_tokenizer.word_index) + 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59449"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCABULARY_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amz_X_train_tk = pad_sequences(amz_X_train_tk, maxlen=MAX_SEQ_LENGTH, padding=\"pre\", truncating=\"post\")\n",
    "amz_X_test_tk = pad_sequences(amz_X_test_tk, maxlen=MAX_SEQ_LENGTH, padding=\"pre\", truncating=\"post\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo sin uso de pos tag\n",
    "Se entrega unicamente las reviews tokenizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 100, 100)          5944900   \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 94, 128)           89728     \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 88, 128)           114816    \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 88, 128)          512       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 88, 128)           0         \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 42, 128)          0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 38, 64)            41024     \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 34, 64)            20544     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 34, 64)           256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 34, 64)            0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2176)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 5)                 10885     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,222,665\n",
      "Trainable params: 6,222,281\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "amz_model = Sequential([\n",
    "          layers.Embedding(input_dim=VOCABULARY_SIZE, \n",
    "                           output_dim=EMBEDDING_SIZE, \n",
    "                           input_length=MAX_SEQ_LENGTH,\n",
    "                          ),\n",
    "          layers.Conv1D(128, 7, activation='relu'),\n",
    "          layers.Conv1D(128,7, activation='relu'),\n",
    "          layers.BatchNormalization(),\n",
    "          layers.Dropout(0.25),\n",
    "          layers.MaxPooling1D(pool_size=5, strides = 2),\n",
    "          layers.Conv1D(64,5, activation='relu'),\n",
    "          layers.Conv1D(64,5, activation='relu'),\n",
    "          layers.BatchNormalization(),\n",
    "          layers.Dropout(0.25),\n",
    "          layers.Flatten(),\n",
    "          # layers.Dropout(0.5),\n",
    "          # layers.LSTM(100, dropout=0.2, recurrent_dropout=0.2),\n",
    "          layers.Dense(5, activation='softmax'),\n",
    "    ])\n",
    "amz_model.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "amz_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "926/926 [==============================] - 84s 85ms/step - loss: 1.2323 - accuracy: 0.4881 - val_loss: 1.3163 - val_accuracy: 0.4700\n",
      "Epoch 2/7\n",
      "926/926 [==============================] - 57s 61ms/step - loss: 0.9457 - accuracy: 0.6205 - val_loss: 0.9712 - val_accuracy: 0.6160\n",
      "Epoch 3/7\n",
      "926/926 [==============================] - 58s 63ms/step - loss: 0.7638 - accuracy: 0.7000 - val_loss: 0.9617 - val_accuracy: 0.6281\n",
      "Epoch 4/7\n",
      "926/926 [==============================] - 56s 60ms/step - loss: 0.5936 - accuracy: 0.7722 - val_loss: 1.0995 - val_accuracy: 0.6147\n",
      "Epoch 5/7\n",
      "926/926 [==============================] - 55s 59ms/step - loss: 0.4604 - accuracy: 0.8262 - val_loss: 1.3290 - val_accuracy: 0.5959\n",
      "Epoch 6/7\n",
      "926/926 [==============================] - 54s 59ms/step - loss: 0.3644 - accuracy: 0.8637 - val_loss: 1.5047 - val_accuracy: 0.5925\n",
      "Epoch 7/7\n",
      "926/926 [==============================] - 53s 58ms/step - loss: 0.2986 - accuracy: 0.8900 - val_loss: 1.4067 - val_accuracy: 0.6391\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ea28cc8910>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amz_model.fit(amz_X_train_tk, amz_y_train, epochs = 7, validation_data=(amz_X_test_tk, amz_y_test), batch_size=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pos Tagging las reviews\n",
    "Se hacen predicciones con el modelo de pos taggin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word_tokenizer.texts_to_sequences(X_train)\n",
    "amz_X_train_tagged=postag_model.predict(amz_X_train_tk)\n",
    "amz_X_test_tagged=postag_model.predict(amz_X_test_tk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tag(data):\n",
    "    decod_pred=[]\n",
    "    for p in np.argmax(data,axis=2):\n",
    "        aux=[]\n",
    "        for i in p:\n",
    "            if i !=0:\n",
    "                aux.append(i)\n",
    "            else:\n",
    "                aux.append(12)\n",
    "                #aux.append(tag_tokenizer.index_word[i])\n",
    "        decod_pred.append(np.array(aux))\n",
    "    return np.array(decod_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amz_xtrain_decod=get_tag(amz_X_train_tagged)\n",
    "amz_xtest_decod=get_tag(amz_X_test_tagged)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenando los pos tag a las reviews\n",
    "Se unen los array de reviews y pos tag tokenizados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amz_x_train_final = np.hstack([amz_X_train_tk, amz_xtrain_decod])\n",
    "amz_x_test_final=np.hstack([amz_X_test_tk, amz_xtest_decod])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo con reviews + pos tag\n",
    "Se pasa el nuevo arreglo de reviews y sus respectivos pos tag juntos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 200, 100)          5944900   \n",
      "                                                                 \n",
      " conv1d_4 (Conv1D)           (None, 194, 128)          89728     \n",
      "                                                                 \n",
      " conv1d_5 (Conv1D)           (None, 188, 128)          114816    \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 188, 128)         512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 188, 128)          0         \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPooling  (None, 92, 128)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_6 (Conv1D)           (None, 88, 64)            41024     \n",
      "                                                                 \n",
      " conv1d_7 (Conv1D)           (None, 84, 64)            20544     \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 84, 64)           256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 84, 64)            0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 5376)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 5)                 26885     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,238,665\n",
      "Trainable params: 6,238,281\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "amz_model2 = Sequential([\n",
    "          layers.Embedding(input_dim=VOCABULARY_SIZE, \n",
    "                           output_dim=EMBEDDING_SIZE, \n",
    "                           input_length=MAX_SEQ_LENGTH*2,\n",
    "                          ),\n",
    "          layers.Conv1D(128, 7, activation='relu'),\n",
    "          layers.Conv1D(128,7, activation='relu'),\n",
    "          layers.BatchNormalization(),\n",
    "          layers.Dropout(0.25),\n",
    "          layers.MaxPooling1D(pool_size=5, strides = 2),\n",
    "          layers.Conv1D(64,5, activation='relu'),\n",
    "          layers.Conv1D(64,5, activation='relu'),\n",
    "          layers.BatchNormalization(),\n",
    "          layers.Dropout(0.25),\n",
    "          layers.Flatten(),\n",
    "          layers.Dense(5, activation='softmax'),\n",
    "    ])\n",
    "amz_model2.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "amz_model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "926/926 [==============================] - 89s 95ms/step - loss: 1.2205 - accuracy: 0.5007 - val_loss: 1.0505 - val_accuracy: 0.5636\n",
      "Epoch 2/7\n",
      "926/926 [==============================] - 86s 93ms/step - loss: 0.9089 - accuracy: 0.6372 - val_loss: 0.9654 - val_accuracy: 0.6363\n",
      "Epoch 3/7\n",
      "926/926 [==============================] - 87s 94ms/step - loss: 0.7052 - accuracy: 0.7268 - val_loss: 1.0113 - val_accuracy: 0.6164\n",
      "Epoch 4/7\n",
      "926/926 [==============================] - 88s 95ms/step - loss: 0.5224 - accuracy: 0.8021 - val_loss: 1.0613 - val_accuracy: 0.6482\n",
      "Epoch 5/7\n",
      "926/926 [==============================] - 88s 95ms/step - loss: 0.3910 - accuracy: 0.8545 - val_loss: 1.1147 - val_accuracy: 0.6734\n",
      "Epoch 6/7\n",
      "926/926 [==============================] - 88s 95ms/step - loss: 0.2974 - accuracy: 0.8915 - val_loss: 1.3356 - val_accuracy: 0.6702\n",
      "Epoch 7/7\n",
      "926/926 [==============================] - 89s 96ms/step - loss: 0.2382 - accuracy: 0.9134 - val_loss: 1.4399 - val_accuracy: 0.6758\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ea2f008d30>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amz_model2.fit(amz_x_train_final, amz_y_train, epochs = 7, validation_data=(amz_x_test_final, amz_y_test), batch_size=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMDB Movie reviews sentiment\n",
    "\n",
    "Dataset con reviews sobre peliculas que son etiquetados como positivas o negativas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://ai.stanford.edu/~amaas/data/sentiment/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('data2/IMDB_Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>I thought this movie did a down right good job...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>I am a Catholic taught in parochial elementary...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>I'm going to have to disagree with the previou...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>No one expects the Star Trek movies to be high...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "0      One of the other reviewers has mentioned that ...  positive\n",
       "1      A wonderful little production. <br /><br />The...  positive\n",
       "2      I thought this was a wonderful way to spend ti...  positive\n",
       "3      Basically there's a family where a little boy ...  negative\n",
       "4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
       "...                                                  ...       ...\n",
       "49995  I thought this movie did a down right good job...  positive\n",
       "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
       "49997  I am a Catholic taught in parochial elementary...  negative\n",
       "49998  I'm going to have to disagree with the previou...  negative\n",
       "49999  No one expects the Star Trek movies to be high...  negative\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.<br /><br />The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.<br /><br />It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary. It focuses mainly on Emerald City, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. Em City is home to many..Aryans, Muslims, gangstas, Latinos, Christians, Italians, Irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.<br /><br />I would say the main appeal of the show is due to the fact that it goes where other shows wouldn't dare. Forget pretty pictures painted for mainstream audiences, forget charm, forget romance...OZ doesn't mess around. The first episode I ever saw struck me as so nasty it was surreal, I couldn't say I was ready for it, but as I watched more, I developed a taste for Oz, and got accustomed to the high levels of graphic violence. Not just violence, but injustice (crooked guards who'll be sold out for a nickel, inmates who'll kill on order and get away with it, well mannered, middle class inmates being turned into prison bitches due to their lack of street skills or prison experience) Watching Oz, you may become comfortable with what is uncomfortable viewing....thats if you can get in touch with your darker side.\""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.iloc[0].review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#limpiando texto\n",
    "df2.review = df2.review.apply(lambda row: cleaner(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encodeando label\n",
    "df2.sentiment = df2.sentiment.apply(lambda row: 1 if row == 'positive' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df2.review\n",
    "Y = df2.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distribucion de clases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABYEAAALLCAYAAACvq00xAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAApLklEQVR4nO3de7Sld13f8c+XTIJcZBFgjDEXDRDRoDVCGqK0NlVXMrCWDVih0KWMiMYuQaFSC6IQ5FIvrdCiSAsSE1CJKCopxsQYQ8FaIBGQJFyaaQCTyCUXbhUEA9/+cZ7o6XgmmUzOZfI9r9dae529v8/z7P3b89es93rWb1d3BwAAAACAme621QsAAAAAAGDjiMAAAAAAAIOJwAAAAAAAg4nAAAAAAACDicAAAAAAAIOJwAAAAAAAg4nAAABsC1X1/VXVqx5frKrrq+r1VfWQA3i/c6rqQxuwVAAAWFc7tnoBAACwyR6X5LokhyR5UJLnJrmkqh7a3Z/a0pUBAMAGEIEBANhu3t3de5bn/7Oq/irJxUm+Nckfbt2yAABgY9gOAgCA7e7Ty99Dk6SqHlxVr62qD1bV56rqmqp6RVUdfntvVFU/U1XvrKpPV9WNVfUnVXXKXuecumxH8S+q6peX826sql+vqvvude6OqnpWVb23qv6mqm6oqgur6utWnbOzqv7rsrXF56vq/VV15p3/ZwEAYAp3AgMAsN0cUlU7srIdxAOT/IckH0/y5uX4VyW5NskzknxiOec5SS5I8i23895HJXlpVrabuFeS703ylqp6eHdfsde5/yXJm5L86yQPSfILSb6YZPeqc85L8pgk/znJHyf5siTfluTIJO+vqvsk+dMk90jy/CQfTHJ6kldU1d27+5du918DAIDxqru3eg0AALDhqur7k/zaGof+KsljuvuyfVy3I8kpSd6a5GHd/a5lfk6SU7v7a/Zx3SFJKslVSS7s7qcv81OTXJrkNd29e9X5v5zkB5Pco7u7qr49ySVJnt7dL9vHZzw3yU8l+cbuvnrV/FVJHpvkK7v7lrWuBQBg+7AdBAAA281jk/zjJCdn5S7b9ya5oKq+Pkmq6rCqes6yrcLnkvxtVgJwsnLH7j5V1XdW1aVVdVOSW5Zrv3Yf1/3BXq+vSHL3JEcsr09L0kledRsfuSvJ25N8cNk6YscSrS9Kcv8kJ9zWegEA2B5sBwEAwHZz5aofhktV/VFWtn94fpJ/leRnk/xokhck+bMkn0lydJLfzcp2DGuqqodlZcuIi5I8JclHsrK9w6/u47qb93r9+eXvrefeP8nN3f252/guX5HkwVmJzWu5/21cCwDANiECAwCwrXX356rqmiT/aBk9IStbNbzo1nOq6t778Vb/Mit3/353d/9dlF1+UO6TB7C0G5Pcr6rucRsh+Kas7Gf89H0c/8ABfC4AAMPYDgIAgG2tqu6Z5EFJblhG98w/vLP2yfvxVvfMyp2/f/ejG8u+vsce4NL+KCt7Cv/gbZxzYZKvS/KX3X35Go/PHOBnAwAwiDuBAQDYbk6sqgdkJbAemeRpSe6X5JeW4xcm2V1VVyTZk+S7k3zrfrzvhUmekeScqvq1rOwF/Nwk1x/IIrv70qp6Q5KXVNUxSf4kyaFJvi3JH3T3m5O8NCtbWLy1ql6alTt/75WVMPxPu/uMA/lsAABmEYEBANhufnvV8xuSXJlkV3dftMx+NCuB+MXL6wuSPDHJO27rTbv7oqr6sSQ/npWtIa5M8qQkP30n1vqEJM9KsjsrgflTSS7Lyj7D6e5PVdW3Jnnect5RWdl64gNJ3nAnPhcAgEGqu2//LAAAAAAA7pLsCQwAAAAAMJgIDAAAAAAwmAgMAAAAADCYCAwAAAAAMJgIDAAAAAAw2I6tXsBW2rVrV1944YVbvQwAAAAAgDur9nVgW98JfOONN271EgAAAAAANtS2jsAAAAAAANOJwAAAAAAAg4nAAAAAAACDicAAAAAAAIOJwAAAAAAAg4nAAAAAAACDicAAAAAAAIOJwAAAAAAAg4nAAAAAAACDicAAAAAAAIOJwAAAAAAAg4nAAAAAAACDicAAAAAAAIOJwAAAAAAAg4nAAAAAAACDicAAAAAAAIOJwAAAAAAAg4nAAAAAAACDicAAAAAAAIOJwAAAAAAAg4nAAAAAAACDicAAAAAAAIOJwAAAAAAAg4nAAAAAAACDicAAAAAAAINtSgSuqmOq6tKqem9VXVVVT1/mz6+q66vq3cvj0auu+cmq2lNVH6iq01fNdy2zPVX17FXz46rq7cv8t6rqsM34bgAAAAAAB7PNuhP4liTP7O4TkpyS5KlVdcJy7KXdfeLyuCBJlmNPSPLQJLuS/EpVHVJVhyR5eZJHJTkhyRNXvc/PL+/14CSfSPKUTfpuAAAAAAAHrU2JwN39ke5+5/L8M0nel+So27jkjCTndffnu/uDSfYkOXl57Onua7r7C0nOS3JGVVWSb0/yO8v15yZ5zIZ8GQAAAACAu5BN3xO4qr4myTcnefsyelpVvaeqzq6qw5fZUUmuXXXZdctsX/P7J/lkd9+y1xwAAAAAYFvbsZkfVlX3TvKGJM/o7k9X1SuSvDBJL39/MckPbPAazkxyZpIce+yxG/lRdykP/4nXbPUSAIBB/vw/Pmmrl8BB6C9f8I1bvQQAYJhjn3fFVi/hLmHT7gSuqkOzEoB/o7t/N0m6+2Pd/cXu/lKSV2Vlu4ckuT7JMasuP3qZ7Wt+U5L7VtWOveb/QHe/srtP6u6Tdu7cuT5fDgAAAADgILUpEXjZs/fVSd7X3S9ZNT9y1WmPTXLl8vz8JE+oqrtX1XFJjk/yjiSXJTm+qo6rqsOy8uNx53d3J7k0yfcs1+9O8saN/E4AAAAAAHcFm7UdxCOTfF+SK6rq3cvsOUmeWFUnZmU7iA8l+eEk6e6rqur1Sd6b5JYkT+3uLyZJVT0tyUVJDklydndftbzfs5KcV1UvSvKurERnAAAAAIBtbVMicHf/aZJa49AFt3HNi5O8eI35BWtd193X5O+3kwAAAAAAIJu4JzAAAAAAAJtPBAYAAAAAGEwEBgAAAAAYTAQGAAAAABhMBAYAAAAAGEwEBgAAAAAYTAQGAAAAABhMBAYAAAAAGEwEBgAAAAAYTAQGAAAAABhMBAYAAAAAGEwEBgAAAAAYTAQGAAAAABhMBAYAAAAAGEwEBgAAAAAYTAQGAAAAABhMBAYAAAAAGEwEBgAAAAAYTAQGAAAAABhMBAYAAAAAGEwEBgAAAAAYTAQGAAAAABhMBAYAAAAAGEwEBgAAAAAYTAQGAAAAABhMBAYAAAAAGEwEBgAAAAAYTAQGAAAAABhMBAYAAAAAGEwEBgAAAAAYTAQGAAAAABhMBAYAAAAAGEwEBgAAAAAYTAQGAAAAABhMBAYAAAAAGEwEBgAAAAAYTAQGAAAAABhMBAYAAAAAGEwEBgAAAAAYTAQGAAAAABhMBAYAAAAAGEwEBgAAAAAYTAQGAAAAABhMBAYAAAAAGEwEBgAAAAAYTAQGAAAAABhMBAYAAAAAGEwEBgAAAAAYTAQGAAAAABhMBAYAAAAAGEwEBgAAAAAYTAQGAAAAABhMBAYAAAAAGEwEBgAAAAAYTAQGAAAAABhMBAYAAAAAGEwEBgAAAAAYTAQGAAAAABhMBAYAAAAAGEwEBgAAAAAYTAQGAAAAABhMBAYAAAAAGEwEBgAAAAAYTAQGAAAAABhMBAYAAAAAGEwEBgAAAAAYTAQGAAAAABhMBAYAAAAAGEwEBgAAAAAYTAQGAAAAABhMBAYAAAAAGEwEBgAAAAAYTAQGAAAAABhMBAYAAAAAGEwEBgAAAAAYTAQGAAAAABhMBAYAAAAAGEwEBgAAAAAYTAQGAAAAABhMBAYAAAAAGEwEBgAAAAAYTAQGAAAAABhMBAYAAAAAGEwEBgAAAAAYTAQGAAAAABhMBAYAAAAAGEwEBgAAAAAYTAQGAAAAABhMBAYAAAAAGEwEBgAAAAAYTAQGAAAAABhMBAYAAAAAGEwEBgAAAAAYTAQGAAAAABhMBAYAAAAAGEwEBgAAAAAYTAQGAAAAABhMBAYAAAAAGEwEBgAAAAAYTAQGAAAAABhMBAYAAAAAGEwEBgAAAAAYTAQGAAAAABhMBAYAAAAAGEwEBgAAAAAYTAQGAAAAABhMBAYAAAAAGEwEBgAAAAAYTAQGAAAAABhMBAYAAAAAGEwEBgAAAAAYTAQGAAAAABhMBAYAAAAAGEwEBgAAAAAYTAQGAAAAABhMBAYAAAAAGGxTInBVHVNVl1bVe6vqqqp6+jK/X1VdXFVXL38PX+ZVVS+rqj1V9Z6qetiq99q9nH91Ve1eNX94VV2xXPOyqqrN+G4AAAAAAAezzboT+JYkz+zuE5KckuSpVXVCkmcnuaS7j09yyfI6SR6V5PjlcWaSVyQr0TjJWUkekeTkJGfdGo6Xc35o1XW7NuF7AQAAAAAc1DYlAnf3R7r7ncvzzyR5X5KjkpyR5NzltHOTPGZ5fkaS1/SKtyW5b1UdmeT0JBd3983d/YkkFyfZtRy7T3e/rbs7yWtWvRcAAAAAwLa16XsCV9XXJPnmJG9PckR3f2Q59NEkRyzPj0py7arLrltmtzW/bo35Wp9/ZlVdXlWX33DDDXfuywAAAAAAHOQ2NQJX1b2TvCHJM7r706uPLXfw9kavobtf2d0ndfdJO3fu3OiPAwAAAADYUpsWgavq0KwE4N/o7t9dxh9btnLI8vfjy/z6JMesuvzoZXZb86PXmAMAAAAAbGubEoGrqpK8Osn7uvslqw6dn2T38nx3kjeumj+pVpyS5FPLthEXJTmtqg5ffhDutCQXLcc+XVWnLJ/1pFXvBQAAAACwbe3YpM95ZJLvS3JFVb17mT0nyc8leX1VPSXJh5M8fjl2QZJHJ9mT5LNJnpwk3X1zVb0wyWXLeS/o7puX5z+S5Jwk90jyh8sDAAAAAGBb25QI3N1/mqT2cfg71ji/kzx1H+91dpKz15hfnuQb7sQyAQAAAADG2dQfhgMAAAAAYHOJwAAAAAAAg4nAAAAAAACDicAAAAAAAIOJwAAAAAAAg4nAAAAAAACDicAAAAAAAIOJwAAAAAAAg4nAAAAAAACDicAAAAAAAIOJwAAAAAAAg4nAAAAAAACDicAAAAAAAIOJwAAAAAAAg4nAAAAAAACDicAAAAAAAIOJwAAAAAAAg4nAAAAAAACDicAAAAAAAIOJwAAAAAAAg4nAAAAAAACDicAAAAAAAIOJwAAAAAAAg4nAAAAAAACDicAAAAAAAIOJwAAAAAAAg4nAAAAAAACDicAAAAAAAIOJwAAAAAAAg4nAAAAAAACDicAAAAAAAIOJwAAAAAAAg4nAAAAAAACDicAAAAAAAIOJwAAAAAAAg4nAAAAAAACDicAAAAAAAIOJwAAAAAAAg4nAAAAAAACDicAAAAAAAIOJwAAAAAAAg4nAAAAAAACDicAAAAAAAIOJwAAAAAAAg4nAAAAAAACDicAAAAAAAIOJwAAAAAAAg4nAAAAAAACDicAAAAAAAIOJwAAAAAAAg4nAAAAAAACDicAAAAAAAIOJwAAAAAAAg4nAAAAAAACDicAAAAAAAIOJwAAAAAAAg4nAAAAAAACDicAAAAAAAIOJwAAAAAAAg4nAAAAAAACDicAAAAAAAIOJwAAAAAAAg4nAAAAAAACDicAAAAAAAIOJwAAAAAAAg4nAAAAAAACDicAAAAAAAIOJwAAAAAAAg4nAAAAAAACDicAAAAAAAIOJwAAAAAAAg4nAAAAAAACDicAAAAAAAIOJwAAAAAAAg4nAAAAAAACDicAAAAAAAIOJwAAAAAAAg4nAAAAAAACDicAAAAAAAIOJwAAAAAAAg4nAAAAAAACDicAAAAAAAIOJwAAAAAAAg4nAAAAAAACDicAAAAAAAIOJwAAAAAAAg4nAAAAAAACDicAAAAAAAIOJwAAAAAAAg4nAAAAAAACDicAAAAAAAIOJwAAAAAAAg4nAAAAAAACDicAAAAAAAIOJwAAAAAAAg4nAAAAAAACDicAAAAAAAIOJwAAAAAAAg4nAAAAAAACDicAAAAAAAIOJwAAAAAAAg4nAAAAAAACDicAAAAAAAIOJwAAAAAAAg4nAAAAAAACDicAAAAAAAIOJwAAAAAAAg4nAAAAAAACDicAAAAAAAIOJwAAAAAAAg4nAAAAAAACDicAAAAAAAIOJwAAAAAAAg4nAAAAAAACDicAAAAAAAINtSgSuqrOr6uNVdeWq2fOr6vqqevfyePSqYz9ZVXuq6gNVdfqq+a5ltqeqnr1qflxVvX2Z/1ZVHbYZ3wsAAAAA4GC3WXcCn5Nk1xrzl3b3icvjgiSpqhOSPCHJQ5drfqWqDqmqQ5K8PMmjkpyQ5InLuUny88t7PTjJJ5I8ZUO/DQAAAADAXcSmRODufkuSm/fz9DOSnNfdn+/uDybZk+Tk5bGnu6/p7i8kOS/JGVVVSb49ye8s15+b5DHruX4AAAAAgLuqrd4T+GlV9Z5lu4jDl9lRSa5ddc51y2xf8/sn+WR337LXHAAAAABg29vKCPyKJA9KcmKSjyT5xc340Ko6s6our6rLb7jhhs34SAAAAACALbNlEbi7P9bdX+zuLyV5VVa2e0iS65Mcs+rUo5fZvuY3JblvVe3Ya76vz31ld5/U3Sft3Llzfb4MAAAAAMBBassicFUduerlY5NcuTw/P8kTquruVXVckuOTvCPJZUmOr6rjquqwrPx43Pnd3UkuTfI9y/W7k7xxM74DAAAAAMDBbsftn3LnVdXrkpya5AFVdV2Ss5KcWlUnJukkH0ryw0nS3VdV1euTvDfJLUme2t1fXN7naUkuSnJIkrO7+6rlI56V5LyqelGSdyV59WZ8LwAAAACAg92mRODufuIa432G2u5+cZIXrzG/IMkFa8yvyd9vJwEAAAAAwGIrfxgOAAAAAIANJgIDAAAAAAwmAgMAAAAADCYCAwAAAAAMJgIDAAAAAAwmAgMAAAAADCYCAwAAAAAMJgIDAAAAAAwmAgMAAAAADCYCAwAAAAAMJgIDAAAAAAwmAgMAAAAADCYCAwAAAAAMJgIDAAAAAAwmAgMAAAAADCYCAwAAAAAMJgIDAAAAAAwmAgMAAAAADCYCAwAAAAAMJgIDAAAAAAwmAgMAAAAADCYCAwAAAAAMJgIDAAAAAAwmAgMAAAAADCYCAwAAAAAMtt8RuKoet4/596zfcgAAAAAAWE935E7gV+9j/sr1WAgAAAAAAOtvx+2dUFUPXJ7eraqOS1KrDj8wyd9sxMIAAAAAALjzbjcCJ9mTpLMSf//PXsc+muT567wmAAAAAADWye1G4O6+W5JU1f/o7n+28UsCAAAAAGC97PeewAIwAAAAAMBdz/5sB5EkWfYDfnGSE5Pce/Wx7j52fZcFAAAAAMB62O8InOQ3s7In8DOTfHZjlgMAAAAAwHq6IxH4oUke2d1f2qjFAAAAAACwvvZ7T+Akb0nyzRu1EAAAAAAA1t8duRP4Q0kurKrfS/LR1Qe6+3nruSgAAAAAANbHHYnA90rypiSHJjlmY5YDAAAAAMB62u8I3N1P3siFAAAAAACw/vY7AlfVA/d1rLuvWZ/lAAAAAACwnu7IdhB7knSSWjXr5e8h67YiAAAAAADWzR3ZDuJuq19X1VcmOSvJW9d7UQAAAAAArI+73f4pa+vujyZ5RpKfXbfVAAAAAACwrg44Ai8ekuSe67EQAAAAAADW3x35Ybi35u/3AE5W4u9Dk7xgvRcFAAAAAMD6uCM/DPere73+6yR/0d1Xr+N6AAAAAABYR3fkh+HO3ciFAAAAAACw/vZ7T+CqOrSqfqaqrqmqv1n+/kxVHbaRCwQAAAAA4MDdke0gfiHJyUn+TZIPJ/nqJM9Ncp8k/3b9lwYAAAAAwJ11RyLw45J8U3fftLz+QFW9M8lfRAQGAAAAADgo7fd2EEnqDs4BAAAAANhidyQC/3aS/15Vp1fV11fVriS/v8wBAAAAADgI3ZHtIP59kp9O8vIkX5Xk+iSvS/KiDVgXAAAAAADr4HbvBK6qR1bVz3f3F7r7ed394O6+Z3cfn+TuSR628csEAAAAAOBA7M92EM9J8pZ9HLs0yU+t33IAAAAAAFhP+xOBT0xy4T6O/XGSh6/bagAAAAAAWFf7E4Hvk+SwfRw7NMmXr99yAAAAAABYT/sTgd+f5LR9HDttOQ4AAAAAwEFox36c89Ik/62qDkny+939paq6W5LHJHl5kh/fwPUBAAAAAHAn3G4E7u7frKqvTHJukrtX1Y1JHpDk80nO6u7XbfAaAQAAAAA4QPtzJ3C6+yVV9atJviXJ/ZPclOR/dfenN3JxAAAAAADcOfsVgZNkCb4XbeBaAAAAAABYZ/vzw3AAAAAAANxFicAAAAAAAIOJwAAAAAAAg4nAAAAAAACDicAAAAAAAIOJwAAAAAAAg4nAAAAAAACDicAAAAAAAIOJwAAAAAAAg4nAAAAAAACDicAAAAAAAIOJwAAAAAAAg4nAAAAAAACDicAAAAAAAIOJwAAAAAAAg4nAAAAAAACDicAAAAAAAIOJwAAAAAAAg4nAAAAAAACDicAAAAAAAIOJwAAAAAAAg4nAAAAAAACDicAAAAAAAIOJwAAAAAAAg4nAAAAAAACDicAAAAAAAIOJwAAAAAAAg4nAAAAAAACDicAAAAAAAIOJwAAAAAAAg4nAAAAAAACDicAAAAAAAIOJwAAAAAAAg4nAAAAAAACDicAAAAAAAIOJwAAAAAAAg4nAAAAAAACDicAAAAAAAIOJwAAAAAAAg4nAAAAAAACDicAAAAAAAIOJwAAAAAAAg4nAAAAAAACDicAAAAAAAIOJwAAAAAAAg4nAAAAAAACDicAAAAAAAIOJwAAAAAAAg4nAAAAAAACDicAAAAAAAIOJwAAAAAAAg4nAAAAAAACDicAAAAAAAIOJwAAAAAAAg21KBK6qs6vq41V15arZ/arq4qq6evl7+DKvqnpZVe2pqvdU1cNWXbN7Of/qqtq9av7wqrpiueZlVVWb8b0AAAAAAA52m3Un8DlJdu01e3aSS7r7+CSXLK+T5FFJjl8eZyZ5RbISjZOcleQRSU5Octat4Xg554dWXbf3ZwEAAAAAbEubEoG7+y1Jbt5rfEaSc5fn5yZ5zKr5a3rF25Lct6qOTHJ6kou7++bu/kSSi5PsWo7dp7vf1t2d5DWr3gsAAAAAYFvbyj2Bj+jujyzPP5rkiOX5UUmuXXXedcvstubXrTEHAAAAANj2Doofhlvu4O3N+KyqOrOqLq+qy2+44YbN+EgAAAAAgC2zlRH4Y8tWDln+fnyZX5/kmFXnHb3Mbmt+9BrzNXX3K7v7pO4+aefOnXf6SwAAAAAAHMy2MgKfn2T38nx3kjeumj+pVpyS5FPLthEXJTmtqg5ffhDutCQXLcc+XVWnVFUledKq9wIAAAAA2NZ2bMaHVNXrkpya5AFVdV2Ss5L8XJLXV9VTknw4yeOX0y9I8ugke5J8NsmTk6S7b66qFya5bDnvBd1964/N/UiSc5LcI8kfLg8AAAAAgG1vUyJwdz9xH4e+Y41zO8lT9/E+Zyc5e4355Um+4c6sEQAAAABgooPih+EAAAAAANgYIjAAAAAAwGAiMAAAAADAYCIwAAAAAMBgIjAAAAAAwGAiMAAAAADAYCIwAAAAAMBgIjAAAAAAwGAiMAAAAADAYCIwAAAAAMBgIjAAAAAAwGAiMAAAAADAYCIwAAAAAMBgIjAAAAAAwGAiMAAAAADAYCIwAAAAAMBgIjAAAAAAwGAiMAAAAADAYCIwAAAAAMBgIjAAAAAAwGAiMAAAAADAYCIwAAAAAMBgIjAAAAAAwGAiMAAAAADAYCIwAAAAAMBgIjAAAAAAwGAiMAAAAADAYCIwAAAAAMBgIjAAAAAAwGAiMAAAAADAYCIwAAAAAMBgIjAAAAAAwGAiMAAAAADAYCIwAAAAAMBgIjAAAAAAwGAiMAAAAADAYCIwAAAAAMBgIjAAAAAAwGAiMAAAAADAYCIwAAAAAMBgIjAAAAAAwGAiMAAAAADAYCIwAAAAAMBgIjAAAAAAwGAiMAAAAADAYCIwAAAAAMBgIjAAAAAAwGAiMAAAAADAYCIwAAAAAMBgIjAAAAAAwGAiMAAAAADAYCIwAAAAAMBgIjAAAAAAwGAiMAAAAADAYCIwAAAAAMBgIjAAAAAAwGAiMAAAAADAYCIwAAAAAMBgIjAAAAAAwGAiMAAAAADAYCIwAAAAAMBgIjAAAAAAwGAiMAAAAADAYCIwAAAAAMBgIjAAAAAAwGAiMAAAAADAYCIwAAAAAMBgIjAAAAAAwGAiMAAAAADAYCIwAAAAAMBgIjAAAAAAwGAiMAAAAADAYCIwAAAAAMBgIjAAAAAAwGAiMAAAAADAYCIwAAAAAMBgIjAAAAAAwGAiMAAAAADAYCIwAAAAAMBgIjAAAAAAwGAiMAAAAADAYCIwAAAAAMBgIjAAAAAAwGAiMAAAAADAYCIwAAAAAMBgIjAAAAAAwGAiMAAAAADAYCIwAAAAAMBgIjAAAAAAwGAiMAAAAADAYCIwAAAAAMBgIjAAAAAAwGAiMAAAAADAYCIwAAAAAMBgIjAAAAAAwGAiMAAAAADAYCIwAAAAAMBgIjAAAAAAwGAiMAAAAADAYCIwAAAAAMBgIjAAAAAAwGAiMAAAAADAYCIwAAAAAMBgIjAAAAAAwGAiMAAAAADAYCIwAAAAAMBgIjAAAAAAwGAiMAAAAADAYCIwAAAAAMBgIjAAAAAAwGAiMAAAAADAYCIwAAAAAMBgIjAAAAAAwGAiMAAAAADAYCIwAAAAAMBgWx6Bq+pDVXVFVb27qi5fZverqour6url7+HLvKrqZVW1p6reU1UPW/U+u5fzr66q3Vv1fQAAAAAADiZbHoEX/7y7T+zuk5bXz05ySXcfn+SS5XWSPCrJ8cvjzCSvSFaicZKzkjwiyclJzro1HAMAAAAAbGcHSwTe2xlJzl2en5vkMavmr+kVb0ty36o6MsnpSS7u7pu7+xNJLk6ya5PXDAAAAABw0DkYInAn+aOq+vOqOnOZHdHdH1mefzTJEcvzo5Jcu+ra65bZvuYAAAAAANvajq1eQJJ/0t3XV9VXJLm4qt6/+mB3d1X1en3YEprPTJJjjz12vd4WAAAAAOCgtOV3Anf39cvfjyf5vazs6fuxZZuHLH8/vpx+fZJjVl1+9DLb13ytz3tld5/U3Sft3LlzPb8KAAAAAMBBZ0sjcFXdq6q+/NbnSU5LcmWS85PsXk7bneSNy/PzkzypVpyS5FPLthEXJTmtqg5ffhDutGUGAAAAALCtbfV2EEck+b2qunUtv9ndF1bVZUleX1VPSfLhJI9fzr8gyaOT7Eny2SRPTpLuvrmqXpjksuW8F3T3zZv3NQAAAAAADk5bGoG7+5ok37TG/KYk37HGvJM8dR/vdXaSs9d7jQAAAAAAd2VbvicwAAAAAAAbRwQGAAAAABhMBAYAAAAAGEwEBgAAAAAYTAQGAAAAABhMBAYAAAAAGEwEBgAAAAAYTAQGAAAAABhMBAYAAAAAGEwEBgAAAAAYTAQGAAAAABhMBAYAAAAAGEwEBgAAAAAYTAQGAAAAABhMBAYAAAAAGEwEBgAAAAAYTAQGAAAAABhMBAYAAAAAGEwEBgAAAAAYTAQGAAAAABhMBAYAAAAAGEwEBgAAAAAYTAQGAAAAABhMBAYAAAAAGEwEBgAAAAAYTAQGAAAAABhMBAYAAAAAGEwEBgAAAAAYTAQGAAAAABhMBAYAAAAAGEwEBgAAAAAYTAQGAAAAABhMBAYAAAAAGEwEBgAAAAAYTAQGAAAAABhMBAYAAAAAGEwEBgAAAAAYTAQGAAAAABhMBAYAAAAAGEwEBgAAAAAYTAQGAAAAABhMBAYAAAAAGEwEBgAAAAAYTAQGAAAAABhMBAYAAAAAGEwEBgAAAAAYTAQGAAAAABhMBAYAAAAAGEwEBgAAAAAYTAQGAAAAABhMBAYAAAAAGEwEBgAAAAAYTAQGAAAAABhMBAYAAAAAGEwEBgAAAAAYTAQGAAAAABhMBAYAAAAAGEwEBgAAAAAYTAQGAAAAABhMBAYAAAAAGEwEBgAAAAAYTAQGAAAAABhMBAYAAAAAGEwEBgAAAAAYTAQGAAAAABhMBAYAAAAAGEwEBgAAAAAYTAQGAAAAABhMBAYAAAAAGEwEBgAAAAAYTAQGAAAAABhMBAYAAAAAGEwEBgAAAAAYTAQGAAAAABhMBAYAAAAAGEwEBgAAAAAYTAQGAAAAABhMBAYAAAAAGEwEBgAAAAAYTAQGAAAAABhMBAYAAAAAGEwEBgAAAAAYTAQGAAAAABhMBAYAAAAAGEwEBgAAAAAYTAQGAAAAABhMBAYAAAAAGEwEBgAAAAAYTAQGAAAAABhMBAYAAAAAGEwEBgAAAAAYTAQGAAAAABhMBAYAAAAAGEwEBgAAAAAYTAQGAAAAABhMBAYAAAAAGEwEBgAAAAAYTAQGAAAAABhMBAYAAAAAGEwEBgAAAAAYTAQGAAAAABhMBAYAAAAAGEwEBgAAAAAYTAQGAAAAABhMBAYAAAAAGEwEBgAAAAAYTAQGAAAAABhMBAYAAAAAGEwEBgAAAAAYTAQGAAAAABhMBAYAAAAAGEwEBgAAAAAYTAQGAAAAABhMBAYAAAAAGEwEBgAAAAAYTAQGAAAAABhsVASuql1V9YGq2lNVz97q9QAAAAAAbLUxEbiqDkny8iSPSnJCkidW1QlbuyoAAAAAgK01JgInOTnJnu6+pru/kOS8JGds8ZoAAAAAALbUjq1ewDo6Ksm1q15fl+QRe59UVWcmOXN5+X+r6gObsDaASR6Q5MatXgRwcKv/tHurlwDAXZv/cwL756za6hUcTC7s7l1rHZgUgfdLd78yySu3eh0Ad1VVdXl3n7TV6wAAYC7/5wRYX5O2g7g+yTGrXh+9zAAAAAAAtq1JEfiyJMdX1XFVdViSJyQ5f4vXBAAAAACwpcZsB9Hdt1TV05JclOSQJGd391VbvCyAiWypAwDARvN/ToB1VN291WsAAAAAAGCDTNoOAgAAAACAvYjAAAAAAACDicAAAAAAAION+WE4ANZfVX1dkjOSHLWMrk9yfne/b+tWBQAAANwR7gQGYE1V9awk5yWpJO9YHpXkdVX17K1cGwAA20NVPXmr1wAwQXX3Vq8BgINQVf3vJA/t7r/da35Ykqu6+/itWRkAANtFVf1ldx+71esAuKuzHQQA+/KlJF+V5MN7zY9cjgEAwJ1WVe/Z16EkR2zmWgCmEoEB2JdnJLmkqq5Ocu0yOzbJg5M8basWBQDAOEckOT3JJ/aaV5I/2/zlAMwjAgOwpu6+sKq+NsnJ+f9/GO6y7v7i1q0MAIBh3pTk3t397r0PVNWbN301AAPZExgAAAAAYLC7bfUCAAAAAADYOCIwAAAAAMBgIjAAAGyAqnpzVf3gZl8LAAB7E4EBAOB2VNWHquo7t3odAABwIERgAAAAAIDBRGAAADgAVXV4Vb2pqm6oqk8sz4/e67QHVdU7qurTVfXGqrrfqutPqao/q6pPVtVfVNWpm/oFAADYNkRgAAA4MHdL8mtJvjrJsUk+l+SX9zrnSUl+IMmRSW5J8rIkqaqjkvxBkhcluV+Sf5fkDVW1c1NWDgDAtiICAwDAAejum7r7Dd392e7+TJIXJ/lne5322u6+srv/Oslzkzy+qg5J8r1JLujuC7r7S919cZLLkzx6U78EAADbwo6tXgAAANwVVdU9k7w0ya4khy/jL6+qQ7r7i8vra1dd8uEkhyZ5QFbuHn5cVX3XquOHJrl0Y1cNAMB2JAIDAMCBeWaShyR5RHd/tKpOTPKuJLXqnGNWPT82yd8muTErcfi13f1Dm7RWAAC2MdtBAADA/jm0qr7s1kdW7v79XJJPLj/4dtYa13xvVZ2w3DX8giS/s9wl/OtJvquqTq+qQ5b3PHWNH5YDAIA7TQQGAID9c0FWou+tj/smuUdW7ux9W5IL17jmtUnOSfLRJF+W5MeSpLuvTXJGkuckuSErdwb/RPz/HACADVDdvdVrAAAAAABgg7jTAAAAAABgMBEYAAAAAGAwERgAAAAAYDARGAAAAABgMBEYAAAAAGAwERgAAAAAYDARGAAAAABgMBEYAAAAAGAwERgAAAAAYLD/Bw8rzarconOjAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1728x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(24,12))\n",
    "plt.title('Balance', size=16)\n",
    "sns.countplot(x=Y)\n",
    "plt.ylabel('Count', size=12)\n",
    "plt.xlabel('Label', size=12)\n",
    "plt.xticks(rotation=90)\n",
    "sns.despine(top=True, right=True, left=False, bottom=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizando las reviews con el vocabulario del modelo de pos tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train_tk = word_tokenizer.texts_to_sequences(X_train)\n",
    "X_test_tk = word_tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "vocab_len = len(word_tokenizer.word_index) + 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tk = pad_sequences(X_train_tk, maxlen=MAX_SEQ_LENGTH, padding=\"pre\", truncating=\"post\")\n",
    "X_test_tk = pad_sequences(X_test_tk, maxlen=MAX_SEQ_LENGTH, padding=\"pre\", truncating=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 100)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tk.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1464,   848,  2866,  1464,   848,  2866,   963,  1730,   362,\n",
       "         875,  2131,   923,   938,  1730,   946,   676, 12676,   275,\n",
       "       32623,  3355,  4093,  8675, 51990,  1083,  4093,  1181, 32623,\n",
       "        3531,   328, 51990,   720,  6091,   566,  1151,  4771,  3695,\n",
       "         480,  4412,  1097,  8456,    41,  1378,   152,  1243, 53734,\n",
       "        9684, 45138, 18312,  1709, 49622,   184,   421, 18394,  8456,\n",
       "         990,   300,   676,  1021,   185,   790,  1378,  4597,  9647,\n",
       "        1505,    47,  2766,   240,  1517,   549,  1378,  1829, 19909,\n",
       "       32819, 12528,  8614,  1156,  1513,  1221,  2984,  3557, 15485,\n",
       "        1435,  1505,   608,  1221,  1981, 29760,  1079,   821,  4160,\n",
       "        4610,  1181,  2365,  4771,  1151,  8456,  1292,  7252,  1221,\n",
       "         169])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tk[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo sin pos tag\n",
    "Se le entrega unicamente las reviews tokenizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_3 (Embedding)     (None, 100, 100)          5944900   \n",
      "                                                                 \n",
      " conv1d_8 (Conv1D)           (None, 94, 128)           89728     \n",
      "                                                                 \n",
      " conv1d_9 (Conv1D)           (None, 88, 128)           114816    \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 88, 128)          512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 88, 128)           0         \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPooling  (None, 42, 128)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_10 (Conv1D)          (None, 38, 64)            41024     \n",
      "                                                                 \n",
      " conv1d_11 (Conv1D)          (None, 34, 64)            20544     \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 34, 64)           256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 34, 64)            0         \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 2176)              0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 2177      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,213,957\n",
      "Trainable params: 6,213,573\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "          layers.Embedding(input_dim=VOCABULARY_SIZE, \n",
    "                           output_dim=EMBEDDING_SIZE, \n",
    "                           input_length=MAX_SEQ_LENGTH),\n",
    "          layers.Conv1D(128, 7, activation='relu'),\n",
    "          layers.Conv1D(128,7, activation='relu'),\n",
    "          layers.BatchNormalization(),\n",
    "          layers.Dropout(0.25),\n",
    "          layers.MaxPooling1D(pool_size=5, strides = 2),\n",
    "          layers.Conv1D(64,5, activation='relu'),\n",
    "          layers.Conv1D(64,5, activation='relu'),\n",
    "          layers.BatchNormalization(),\n",
    "          layers.Dropout(0.25),\n",
    "          layers.Flatten(),\n",
    "          layers.Dense(1, activation='sigmoid'),\n",
    "    ])\n",
    "model.compile(loss = 'binary_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "1250/1250 [==============================] - 35s 26ms/step - loss: 0.4538 - accuracy: 0.7844 - val_loss: 0.3357 - val_accuracy: 0.8557\n",
      "Epoch 2/7\n",
      "1250/1250 [==============================] - 31s 25ms/step - loss: 0.2541 - accuracy: 0.8985 - val_loss: 0.3701 - val_accuracy: 0.8471\n",
      "Epoch 3/7\n",
      "1250/1250 [==============================] - 31s 25ms/step - loss: 0.1563 - accuracy: 0.9401 - val_loss: 0.4227 - val_accuracy: 0.8501\n",
      "Epoch 4/7\n",
      "1250/1250 [==============================] - 31s 24ms/step - loss: 0.0854 - accuracy: 0.9686 - val_loss: 0.5358 - val_accuracy: 0.8463\n",
      "Epoch 5/7\n",
      "1250/1250 [==============================] - 31s 25ms/step - loss: 0.0589 - accuracy: 0.9790 - val_loss: 0.6036 - val_accuracy: 0.8450\n",
      "Epoch 6/7\n",
      "1250/1250 [==============================] - 32s 26ms/step - loss: 0.0418 - accuracy: 0.9854 - val_loss: 0.7269 - val_accuracy: 0.8427\n",
      "Epoch 7/7\n",
      "1250/1250 [==============================] - 32s 25ms/step - loss: 0.0357 - accuracy: 0.9869 - val_loss: 0.8003 - val_accuracy: 0.8408\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ea2bd1de20>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_tk, y_train.values, epochs = 7, validation_data=(X_test_tk, y_test),batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pos tagging las reviews\n",
    "Se hace un predict con el modelo para pos tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tagged=postag_model.predict(X_train_tk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_tagged=postag_model.predict(X_test_tk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  694,  1664,   103, 11076,  6968,  7036, 20361,   195, 49437,\n",
       "       40622, 14709,   634, 10135,   849,   226,  3557,   140,  2759,\n",
       "        2326,  1572,   713,  3222,  3499,   866,   619,  4472,  5300,\n",
       "        8371,   381,   111,   260, 13877,  1984, 17745,   119,  9326,\n",
       "         424,    41, 27449,   791,  4077,  1278,   119,    39, 46136,\n",
       "       15781,   312,  1028, 10240, 38451,  1916,  4157,  3025,  4373,\n",
       "         171,  2263,   223,  7746,  2189,   474,  3926,  1361, 10772,\n",
       "         809,  1021,  9079, 15688,  2722, 32510,   595,  3325,   416,\n",
       "         169,   869,   274,   716,   206,    81,  4951,   364, 11877,\n",
       "         152, 13404,   218, 22510,  7957,  9588,  5671,  2406,  5016,\n",
       "       33473,   776, 31555,    92,  1239,   640,  5818,  1568,  2351,\n",
       "        2471])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tk[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tag(data):\n",
    "    decod_pred=[]\n",
    "    for p in np.argmax(data,axis=2):\n",
    "        aux=[]\n",
    "        for i in p:\n",
    "            if i !=0:\n",
    "                aux.append(i)\n",
    "            else:\n",
    "                aux.append(12)\n",
    "                #aux.append(tag_tokenizer.index_word[i])\n",
    "        decod_pred.append(np.array(aux))\n",
    "    return np.array(decod_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_decod=get_tag(X_train_tagged)\n",
    "xtest_decod=get_tag(X_test_tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 100)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtest_decod.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatenando las reviews con sus respectivos pos tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_final = np.hstack([X_train_tk,xtrain_decod])\n",
    "x_test_final=np.hstack([X_test_tk,xtest_decod])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 200)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_final.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo para reviws + pos tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_4 (Embedding)     (None, 200, 100)          5944900   \n",
      "                                                                 \n",
      " conv1d_12 (Conv1D)          (None, 194, 128)          89728     \n",
      "                                                                 \n",
      " conv1d_13 (Conv1D)          (None, 188, 128)          114816    \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 188, 128)         512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 188, 128)          0         \n",
      "                                                                 \n",
      " max_pooling1d_3 (MaxPooling  (None, 92, 128)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_14 (Conv1D)          (None, 88, 64)            41024     \n",
      "                                                                 \n",
      " conv1d_15 (Conv1D)          (None, 84, 64)            20544     \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 84, 64)           256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 84, 64)            0         \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 5376)              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 5377      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,217,157\n",
      "Trainable params: 6,216,773\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Embedding(input_dim=vocab_len, output_dim=embed_dim, input_length=MAX_SEQ_LENGTH*2))\n",
    "model2.add(Conv1D(128, 7, activation='relu'))\n",
    "model2.add(Conv1D(128,7, activation='relu'))\n",
    "model2.add(BatchNormalization())\n",
    "model2.add(Dropout(0.25))\n",
    "model2.add(MaxPooling1D(pool_size=5, strides = 2))\n",
    "model2.add(Conv1D(64,5, activation='relu'))\n",
    "model2.add(Conv1D(64,5, activation='relu'))\n",
    "model2.add((BatchNormalization()))\n",
    "model2.add(Dropout(0.25))\n",
    "model2.add(Flatten())\n",
    "model2.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model2.compile(loss = 'binary_crossentropy', optimizer='adam', metrics = ['accuracy'])\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "1250/1250 [==============================] - 42s 32ms/step - loss: 0.4379 - accuracy: 0.8023 - val_loss: 0.4084 - val_accuracy: 0.8042\n",
      "Epoch 2/7\n",
      "1250/1250 [==============================] - 42s 33ms/step - loss: 0.2377 - accuracy: 0.9064 - val_loss: 0.3327 - val_accuracy: 0.8665\n",
      "Epoch 3/7\n",
      "1250/1250 [==============================] - 41s 33ms/step - loss: 0.1377 - accuracy: 0.9473 - val_loss: 0.4196 - val_accuracy: 0.8628\n",
      "Epoch 4/7\n",
      "1250/1250 [==============================] - 40s 32ms/step - loss: 0.0685 - accuracy: 0.9748 - val_loss: 0.6753 - val_accuracy: 0.8399\n",
      "Epoch 5/7\n",
      "1250/1250 [==============================] - 40s 32ms/step - loss: 0.0417 - accuracy: 0.9855 - val_loss: 0.6831 - val_accuracy: 0.8596\n",
      "Epoch 6/7\n",
      "1250/1250 [==============================] - 41s 33ms/step - loss: 0.0314 - accuracy: 0.9890 - val_loss: 0.8380 - val_accuracy: 0.8528\n",
      "Epoch 7/7\n",
      "1250/1250 [==============================] - 41s 33ms/step - loss: 0.0271 - accuracy: 0.9908 - val_loss: 0.7489 - val_accuracy: 0.8593\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ea2f847d00>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(x_train_final, y_train.values, epochs =7, validation_data=(x_test_final, y_test.values), batch_size=32)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
